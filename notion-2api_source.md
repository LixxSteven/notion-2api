# ğŸ“ notion-2api æºç å¯¼å‡º

> å¯¼å‡ºæ—¶é—´ï¼š2026-01-28 21:44:42
> é¡¹ç›®è·¯å¾„ï¼š`C:\dev\notion-2api`

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
notion-2api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_provider.py
â”‚   â”‚   â””â”€â”€ notion_provider.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ sse_utils.py
â”œâ”€â”€ .env.example
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ main.py
â”œâ”€â”€ nginx.conf
â”œâ”€â”€ project_to_md_gui.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ é¡¹ç›®å®Œæ•´ç»“æ„ä»£ç .txt
```

---

## ğŸ“„ æºç æ–‡ä»¶

### `.env.example`

```
# ====================================================================
# notion-2api é…ç½®æ–‡ä»¶æ¨¡æ¿ (æœ€ç»ˆç‰ˆ)
# ====================================================================
#
# è¯·å°†æ­¤æ–‡ä»¶é‡å‘½åä¸º ".env" å¹¶å¡«å…¥æ‚¨çš„å‡­è¯ã€‚
#

# --- æ ¸å¿ƒå®‰å…¨é…ç½® (å¯é€‰) ---
API_MASTER_KEY=your_secret_key_here

# --- éƒ¨ç½²é…ç½® (å¯é€‰) ---
NGINX_PORT=8088

# --- Notion å‡­è¯ (ä»¥ä¸‹å‡ä¸ºå¿…é¡»æˆ–å¼ºçƒˆå»ºè®®è®¾ç½®) ---
# 1) ç²˜è´´ token_v2 çš„å€¼ æˆ– å®Œæ•´ Cookie
NOTION_COOKIE="åœ¨æ­¤å¤„ç²˜è´´ token_v2 å€¼ æˆ– å®Œæ•´ Cookie"

# 2) æ‚¨çš„ Space ID
NOTION_SPACE_ID="åœ¨æ­¤å¤„ç²˜è´´æ‚¨çš„ Space ID"

# 3) æ‚¨çš„ç”¨æˆ· ID (æµè§ˆå™¨å¼€å‘è€…å·¥å…·ä¸­ x-notion-active-user-header çš„å€¼)
NOTION_USER_ID="åœ¨æ­¤å¤„ç²˜è´´æ‚¨çš„ Notion ç”¨æˆ· ID"

# 4) æ‚¨çš„ Notion ç”¨æˆ·å (æ˜¾ç¤ºåœ¨å·¦ä¸Šè§’çš„åç§°)
NOTION_USER_NAME="åˆ©ä»”"

# 5) æ‚¨çš„ Notion ç™»å½•é‚®ç®±
NOTION_USER_EMAIL="q13645947407@gmail.com"

# å¯é€‰ï¼šæƒ³ç»‘å®šçš„é¡µé¢ blockIdã€‚ç•™ç©ºåˆ™ä¸ç»‘å®šç‰¹å®šé¡µé¢ä¸Šä¸‹æ–‡ã€‚
NOTION_BLOCK_ID=""

# å¯é€‰ï¼šæµè§ˆå™¨ä¸­çœ‹åˆ°çš„å®¢æˆ·ç«¯ç‰ˆæœ¬
NOTION_CLIENT_VERSION="23.13.20251011.2037"
```

### `app\core\__init__.py`

```python

```

### `app\core\config.py`

```python
# app/core/config.py
from pydantic_settings import BaseSettings, SettingsConfigDict
from typing import List, Optional

class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding='utf-8',
        extra="ignore"
    )

    APP_NAME: str = "notion-2api"
    APP_VERSION: str = "4.0.0" # æœ€ç»ˆç¨³å®šç‰ˆ
    DESCRIPTION: str = "ä¸€ä¸ªå°† Notion AI è½¬æ¢ä¸ºå…¼å®¹ OpenAI æ ¼å¼ API çš„é«˜æ€§èƒ½ä»£ç†ã€‚"

    API_MASTER_KEY: Optional[str] = None

    # --- Notion å‡­è¯ ---
    NOTION_COOKIE: Optional[str] = None
    NOTION_SPACE_ID: Optional[str] = None
    NOTION_USER_ID: Optional[str] = None
    NOTION_USER_NAME: Optional[str] = None
    NOTION_USER_EMAIL: Optional[str] = None
    NOTION_BLOCK_ID: Optional[str] = None
    NOTION_CLIENT_VERSION: Optional[str] = "23.13.20251011.2037"

    API_REQUEST_TIMEOUT: int = 180
    NGINX_PORT: int = 8088

    # ã€æœ€ç»ˆä¿®æ­£ã€‘æ›´æ–°æ‰€æœ‰å·²çŸ¥çš„æ¨¡å‹åˆ—è¡¨
    DEFAULT_MODEL: str = "claude-sonnet-4.5"
    
    KNOWN_MODELS: List[str] = [
        "claude-sonnet-4.5",
        "gpt-5",
        "claude-opus-4.1",
        "gemini-2.5-flashï¼ˆæœªä¿®å¤ï¼Œä¸å¯ç”¨ï¼‰",
        "gemini-2.5-proï¼ˆæœªä¿®å¤ï¼Œä¸å¯ç”¨ï¼‰",
        "gpt-4.1"
    ]
    
    # ã€æœ€ç»ˆä¿®æ­£ã€‘æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œå¡«å……æ‰€æœ‰æ¨¡å‹çš„çœŸå®åå°åç§°
    MODEL_MAP: dict = {
        "claude-sonnet-4.5": "anthropic-sonnet-alt",
        "gpt-5": "openai-turbo",
        "claude-opus-4.1": "anthropic-opus-4.1",
        "gemini-2.5-flashï¼ˆæœªä¿®å¤ï¼Œä¸å¯ç”¨ï¼‰": "vertex-gemini-2.5-flash",
        "gemini-2.5-proï¼ˆæœªä¿®å¤ï¼Œä¸å¯ç”¨ï¼‰": "vertex-gemini-2.5-pro",
        "gpt-4.1": "openai-gpt-4.1"
    }

settings = Settings()
```

### `app\providers\__init__.py`

```python

```

### `app\providers\base_provider.py`

```python
from abc import ABC, abstractmethod
from typing import Dict, Any, Union
from fastapi.responses import StreamingResponse, JSONResponse

class BaseProvider(ABC):
    @abstractmethod
    async def chat_completion(
        self,
        request_data: Dict[str, Any]
    ) -> Union[StreamingResponse, JSONResponse]:
        pass

    @abstractmethod
    async def get_models(self) -> JSONResponse:
        pass
```

### `app\providers\notion_provider.py`

```python
# app/providers/notion_provider.py
import json
import time
import logging
import uuid
import re
import cloudscraper
from typing import Dict, Any, AsyncGenerator, List, Optional, Tuple
from datetime import datetime

from fastapi import HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.concurrency import run_in_threadpool

from app.core.config import settings
from app.providers.base_provider import BaseProvider
from app.utils.sse_utils import create_sse_data, create_chat_completion_chunk, DONE_CHUNK

# è®¾ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)

class NotionAIProvider(BaseProvider):
    def __init__(self):
        self.scraper = cloudscraper.create_scraper()
        self.api_endpoints = {
            "runInference": "https://www.notion.so/api/v3/runInferenceTranscript",
            "saveTransactions": "https://www.notion.so/api/v3/saveTransactionsFanout"
        }
        
        if not all([settings.NOTION_COOKIE, settings.NOTION_SPACE_ID, settings.NOTION_USER_ID]):
            raise ValueError("é…ç½®é”™è¯¯: NOTION_COOKIE, NOTION_SPACE_ID å’Œ NOTION_USER_ID å¿…é¡»åœ¨ .env æ–‡ä»¶ä¸­å…¨éƒ¨è®¾ç½®ã€‚")

        self._warmup_session()

    def _warmup_session(self):
        try:
            logger.info("æ­£åœ¨è¿›è¡Œä¼šè¯é¢„çƒ­ (Session Warm-up)...")
            headers = self._prepare_headers()
            headers.pop("Accept", None)
            response = self.scraper.get("https://www.notion.so/", headers=headers, timeout=30)
            response.raise_for_status()
            logger.info("ä¼šè¯é¢„çƒ­æˆåŠŸã€‚")
        except Exception as e:
            logger.error(f"ä¼šè¯é¢„çƒ­å¤±è´¥: {e}", exc_info=True)
            
    async def _create_thread(self, thread_type: str) -> str:
        thread_id = str(uuid.uuid4())
        payload = {
            "requestId": str(uuid.uuid4()),
            "transactions": [{
                "id": str(uuid.uuid4()),
                "spaceId": settings.NOTION_SPACE_ID,
                "operations": [{
                    "pointer": {"table": "thread", "id": thread_id, "spaceId": settings.NOTION_SPACE_ID},
                    "path": [],
                    "command": "set",
                    "args": {
                        "id": thread_id, "version": 1, "parent_id": settings.NOTION_SPACE_ID,
                        "parent_table": "space", "space_id": settings.NOTION_SPACE_ID,
                        "created_time": int(time.time() * 1000),
                        "created_by_id": settings.NOTION_USER_ID, "created_by_table": "notion_user",
                        "messages": [], "data": {}, "alive": True, "type": thread_type
                    }
                }]
            }]
        }
        try:
            logger.info(f"æ­£åœ¨åˆ›å»ºæ–°çš„å¯¹è¯çº¿ç¨‹ (type: {thread_type})...")
            response = await run_in_threadpool(
                lambda: self.scraper.post(
                    self.api_endpoints["saveTransactions"],
                    headers=self._prepare_headers(),
                    json=payload,
                    timeout=20
                )
            )
            response.raise_for_status()
            logger.info(f"å¯¹è¯çº¿ç¨‹åˆ›å»ºæˆåŠŸ, Thread ID: {thread_id}")
            return thread_id
        except Exception as e:
            logger.error(f"åˆ›å»ºå¯¹è¯çº¿ç¨‹å¤±è´¥: {e}", exc_info=True)
            raise Exception("æ— æ³•åˆ›å»ºæ–°çš„å¯¹è¯çº¿ç¨‹ã€‚")

    async def chat_completion(self, request_data: Dict[str, Any]):
        stream = request_data.get("stream", True)

        async def stream_generator() -> AsyncGenerator[bytes, None]:
            request_id = f"chatcmpl-{uuid.uuid4()}"
            incremental_fragments: List[str] = []
            final_message: Optional[str] = None
            
            try:
                model_name = request_data.get("model", settings.DEFAULT_MODEL)
                mapped_model = settings.MODEL_MAP.get(model_name, "anthropic-sonnet-alt")
                
                thread_type = "markdown-chat" if mapped_model.startswith("vertex-") else "workflow"
                
                thread_id = await self._create_thread(thread_type)
                payload = self._prepare_payload(request_data, thread_id, mapped_model, thread_type)
                headers = self._prepare_headers()

                role_chunk = create_chat_completion_chunk(request_id, model_name, role="assistant")
                yield create_sse_data(role_chunk)

                def sync_stream_iterator():
                    try:
                        logger.info(f"è¯·æ±‚ Notion AI URL: {self.api_endpoints['runInference']}")
                        logger.info(f"è¯·æ±‚ä½“: {json.dumps(payload, indent=2, ensure_ascii=False)}")
                        
                        response = self.scraper.post(
                            self.api_endpoints['runInference'], headers=headers, json=payload, stream=True,
                            timeout=settings.API_REQUEST_TIMEOUT
                        )
                        response.raise_for_status()
                        for line in response.iter_lines():
                            if line:
                                yield line
                    except Exception as e:
                        yield e

                sync_gen = sync_stream_iterator()
              
                while True:
                    line = await run_in_threadpool(lambda: next(sync_gen, None))
                    if line is None:
                        break
                    if isinstance(line, Exception):
                        raise line

                    parsed_results = self._parse_ndjson_line_to_texts(line)
                    for text_type, content in parsed_results:
                        if text_type == 'final':
                            final_message = content
                        elif text_type == 'incremental':
                            incremental_fragments.append(content)
              
                full_response = ""
                if final_message:
                    full_response = final_message
                    logger.info(f"æˆåŠŸä» record-map æˆ– Gemini patch/event ä¸­æå–åˆ°æœ€ç»ˆæ¶ˆæ¯ã€‚")
                else:
                    full_response = "".join(incremental_fragments)
                    logger.info(f"ä½¿ç”¨æ‹¼æ¥æ‰€æœ‰å¢é‡ç‰‡æ®µçš„æ–¹å¼è·å¾—æœ€ç»ˆæ¶ˆæ¯ã€‚")

                if full_response:
                    cleaned_response = self._clean_content(full_response)
                    logger.info(f"æ¸…æ´—åçš„æœ€ç»ˆå“åº”: {cleaned_response}")
                    chunk = create_chat_completion_chunk(request_id, model_name, content=cleaned_response)
                    yield create_sse_data(chunk)
                else:
                    logger.warning("è­¦å‘Š: Notion è¿”å›çš„æ•°æ®æµä¸­æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆæ–‡æœ¬ã€‚è¯·æ£€æŸ¥æ‚¨çš„ .env é…ç½®æ˜¯å¦å…¨éƒ¨æ­£ç¡®ä¸”å‡­è¯æœ‰æ•ˆã€‚")

                final_chunk = create_chat_completion_chunk(request_id, model_name, finish_reason="stop")
                yield create_sse_data(final_chunk)
                yield DONE_CHUNK

            except Exception as e:
                error_message = f"å¤„ç† Notion AI æµæ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}"
                logger.error(error_message, exc_info=True)
                error_chunk = {"error": {"message": error_message, "type": "internal_server_error"}}
                yield create_sse_data(error_chunk)
                yield DONE_CHUNK

        if stream:
            return StreamingResponse(stream_generator(), media_type="text/event-stream")
        else:
            raise HTTPException(status_code=400, detail="æ­¤ç«¯ç‚¹å½“å‰ä»…æ”¯æŒæµå¼å“åº” (stream=true)ã€‚")

    def _prepare_headers(self) -> Dict[str, str]:
        cookie_source = (settings.NOTION_COOKIE or "").strip()
        cookie_header = cookie_source if "=" in cookie_source else f"token_v2={cookie_source}"

        return {
            "Content-Type": "application/json",
            "Accept": "application/x-ndjson",
            "Cookie": cookie_header,
            "x-notion-space-id": settings.NOTION_SPACE_ID,
            "x-notion-active-user-header": settings.NOTION_USER_ID,
            "x-notion-client-version": settings.NOTION_CLIENT_VERSION,
            "notion-audit-log-platform": "web",
            "Origin": "https://www.notion.so",
            "Referer": "https://www.notion.so/",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
        }

    def _normalize_block_id(self, block_id: str) -> str:
        if not block_id: return block_id
        b = block_id.replace("-", "").strip()
        if len(b) == 32 and re.fullmatch(r"[0-9a-fA-F]{32}", b):
            return f"{b[0:8]}-{b[8:12]}-{b[12:16]}-{b[16:20]}-{b[20:]}"
        return block_id

    def _prepare_payload(self, request_data: Dict[str, Any], thread_id: str, mapped_model: str, thread_type: str) -> Dict[str, Any]:
        req_block_id = request_data.get("notion_block_id") or settings.NOTION_BLOCK_ID
        normalized_block_id = self._normalize_block_id(req_block_id) if req_block_id else None

        context_value: Dict[str, Any] = {
            "timezone": "Asia/Shanghai",
            "spaceId": settings.NOTION_SPACE_ID,
            "userId": settings.NOTION_USER_ID,
            "userEmail": settings.NOTION_USER_EMAIL,
            "currentDatetime": datetime.now().astimezone().isoformat(),
        }
        if normalized_block_id:
            context_value["blockId"] = normalized_block_id

        config_value: Dict[str, Any]
        
        if mapped_model.startswith("vertex-"):
            logger.info(f"æ£€æµ‹åˆ° Gemini æ¨¡å‹ ({mapped_model})ï¼Œåº”ç”¨ç‰¹å®šçš„ config å’Œ contextã€‚")
            context_value.update({
                "userName": f" {settings.NOTION_USER_NAME}",
                "spaceName": f"{settings.NOTION_USER_NAME}çš„ Notion",
                "spaceViewId": "2008eefa-d0dc-80d5-9e67-000623befd8f",
                "surface": "ai_module"
            })
            config_value = {
                "type": thread_type,
                "model": mapped_model,
                "useWebSearch": True,
                "enableAgentAutomations": False, "enableAgentIntegrations": False,
                "enableBackgroundAgents": False, "enableCodegenIntegration": False,
                "enableCustomAgents": False, "enableExperimentalIntegrations": False,
                "enableLinkedDatabases": False, "enableAgentViewVersionHistoryTool": False,
                "searchScopes": [{"type": "everything"}], "enableDatabaseAgents": False,
                "enableAgentComments": False, "enableAgentForms": False,
                "enableAgentMakesFormulas": False, "enableUserSessionContext": False,
                "modelFromUser": True, "isCustomAgent": False
            }
        else:
            context_value.update({
                "userName": settings.NOTION_USER_NAME,
                "surface": "workflows"
            })
            config_value = {
                "type": thread_type,
                "model": mapped_model,
                "useWebSearch": True,
            }

        transcript = [
            {"id": str(uuid.uuid4()), "type": "config", "value": config_value},
            {"id": str(uuid.uuid4()), "type": "context", "value": context_value}
        ]
      
        for msg in request_data.get("messages", []):
            if msg.get("role") == "user":
                transcript.append({
                    "id": str(uuid.uuid4()),
                    "type": "user",
                    "value": [[msg.get("content")]],
                    "userId": settings.NOTION_USER_ID,
                    "createdAt": datetime.now().astimezone().isoformat()
                })
            elif msg.get("role") == "assistant":
                transcript.append({"id": str(uuid.uuid4()), "type": "agent-inference", "value": [{"type": "text", "content": msg.get("content")}]})

        payload = {
            "traceId": str(uuid.uuid4()),
            "spaceId": settings.NOTION_SPACE_ID,
            "transcript": transcript,
            "threadId": thread_id,
            "createThread": False,
            "isPartialTranscript": True,
            "asPatchResponse": True,
            "generateTitle": True,
            "saveAllThreadOperations": True,
            "threadType": thread_type
        }

        if mapped_model.startswith("vertex-"):
            logger.info("ä¸º Gemini è¯·æ±‚æ·»åŠ  debugOverridesã€‚")
            payload["debugOverrides"] = {
                "emitAgentSearchExtractedResults": True,
                "cachedInferences": {},
                "annotationInferences": {},
                "emitInferences": False
            }
        
        return payload

    def _clean_content(self, content: str) -> str:
        if not content:
            return ""
            
        content = re.sub(r'<lang primary="[^"]*"\s*/>\n*', '', content)
        content = re.sub(r'<thinking>[\s\S]*?</thinking>\s*', '', content, flags=re.IGNORECASE)
        content = re.sub(r'<thought>[\s\S]*?</thought>\s*', '', content, flags=re.IGNORECASE)
        
        content = re.sub(r'^.*?Chinese whatmodel I am.*?Theyspecifically.*?requested.*?me.*?to.*?reply.*?in.*?Chinese\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?This.*?is.*?a.*?straightforward.*?question.*?about.*?my.*?identity.*?asan.*?AI.*?assistant\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?Idon\'t.*?need.*?to.*?use.*?any.*?tools.*?for.*?this.*?-\s*it\'s.*?asimple.*?informational.*?response.*?aboutwhat.*?I.*?am\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?Sincethe.*?user.*?asked.*?in.*?Chinese.*?and.*?specifically.*?requested.*?a.*?Chinese.*?response.*?I.*?should.*?respond.*?in.*?Chinese\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?What model are you.*?in Chinese and specifically requesting.*?me.*?to.*?reply.*?in.*?Chinese\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?This.*?is.*?a.*?question.*?about.*?my.*?identity.*?not requiring.*?any.*?tool.*?use.*?I.*?should.*?respond.*?directly.*?to.*?the.*?user.*?in.*?Chinese.*?as.*?requested\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?I.*?should.*?identify.*?myself.*?as.*?Notion.*?AI.*?as.*?mentioned.*?in.*?the.*?system.*?prompt.*?\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?I.*?should.*?not.*?make.*?specific.*?claims.*?about.*?the.*?underlying.*?model.*?architecture.*?since.*?that.*?information.*?is.*?not.*?provided.*?in.*?my.*?context\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        
        return content.strip()

    def _parse_ndjson_line_to_texts(self, line: bytes) -> List[Tuple[str, str]]:
        results: List[Tuple[str, str]] = []
        try:
            s = line.decode("utf-8", errors="ignore").strip()
            if not s: return results
            
            data = json.loads(s)
            logger.debug(f"åŸå§‹å“åº”æ•°æ®: {json.dumps(data, ensure_ascii=False)}")
            
            # æ ¼å¼1: Gemini è¿”å›çš„ markdown-chat äº‹ä»¶
            if data.get("type") == "markdown-chat":
                content = data.get("value", "")
                if content:
                    logger.info("ä» 'markdown-chat' ç›´æ¥äº‹ä»¶ä¸­æå–åˆ°å†…å®¹ã€‚")
                    results.append(('final', content))

            # æ ¼å¼2: Claude å’Œ GPT è¿”å›çš„è¡¥ä¸æµï¼Œä»¥åŠ Gemini çš„ patch æ ¼å¼
            elif data.get("type") == "patch" and "v" in data:
                for operation in data.get("v", []):
                    if not isinstance(operation, dict): continue
                    
                    op_type = operation.get("o")
                    path = operation.get("p", "")
                    value = operation.get("v")
                    
                    # ã€ä¿®æ”¹ã€‘Gemini çš„å®Œæ•´å†…å®¹ patch æ ¼å¼
                    if op_type == "a" and path.endswith("/s/-") and isinstance(value, dict) and value.get("type") == "markdown-chat":
                        content = value.get("value", "")
                        if content:
                            logger.info("ä» 'patch' (Gemini-style) ä¸­æå–åˆ°å®Œæ•´å†…å®¹ã€‚")
                            results.append(('final', content))
                    
                    # ã€ä¿®æ”¹ã€‘Gemini çš„å¢é‡å†…å®¹ patch æ ¼å¼
                    elif op_type == "x" and "/s/" in path and path.endswith("/value") and isinstance(value, str):
                        content = value
                        if content:
                            logger.info(f"ä» 'patch' (Geminiå¢é‡) ä¸­æå–åˆ°å†…å®¹: {content}")
                            results.append(('incremental', content))
                    
                    # ã€ä¿®æ”¹ã€‘Claude å’Œ GPT çš„å¢é‡å†…å®¹ patch æ ¼å¼
                    elif op_type == "x" and "/value/" in path and isinstance(value, str):
                        content = value
                        if content:
                            logger.info(f"ä» 'patch' (Claude/GPTå¢é‡) ä¸­æå–åˆ°å†…å®¹: {content}")
                            results.append(('incremental', content))
                    
                    # ã€ä¿®æ”¹ã€‘Claude å’Œ GPT çš„å®Œæ•´å†…å®¹ patch æ ¼å¼
                    elif op_type == "a" and path.endswith("/value/-") and isinstance(value, dict) and value.get("type") == "text":
                        content = value.get("content", "")
                        if content:
                            logger.info("ä» 'patch' (Claude/GPT-style) ä¸­æå–åˆ°å®Œæ•´å†…å®¹ã€‚")
                            results.append(('final', content))

            # æ ¼å¼3: å¤„ç†record-mapç±»å‹çš„æ•°æ®
            elif data.get("type") == "record-map" and "recordMap" in data:
                record_map = data["recordMap"]
                if "thread_message" in record_map:
                    for msg_id, msg_data in record_map["thread_message"].items():
                        value_data = msg_data.get("value", {}).get("value", {})
                        step = value_data.get("step", {})
                        if not step: continue

                        content = ""
                        step_type = step.get("type")

                        if step_type == "markdown-chat":
                            content = step.get("value", "")
                        elif step_type == "agent-inference":
                            agent_values = step.get("value", [])
                            if isinstance(agent_values, list):
                                for item in agent_values:
                                    if isinstance(item, dict) and item.get("type") == "text":
                                        content = item.get("content", "")
                                        break
                        
                        if content and isinstance(content, str):
                            logger.info(f"ä» record-map (type: {step_type}) æå–åˆ°æœ€ç»ˆå†…å®¹ã€‚")
                            results.append(('final', content))
                            break 
    
        except (json.JSONDecodeError, AttributeError) as e:
            logger.warning(f"è§£æNDJSONè¡Œå¤±è´¥: {e} - Line: {line.decode('utf-8', errors='ignore')}")
        
        return results

    async def get_models(self) -> JSONResponse:
        model_data = {
            "object": "list",
            "data": [
                {"id": name, "object": "model", "created": int(time.time()), "owned_by": "lzA6"}
                for name in settings.KNOWN_MODELS
            ]
        }
        return JSONResponse(content=model_data)
```

### `app\utils\sse_utils.py`

```python
# app/utils/sse_utils.py
import json
import time
from typing import Dict, Any, Optional

DONE_CHUNK = b"data: [DONE]\n\n"

def create_sse_data(data: Dict[str, Any]) -> bytes:
    return f"data: {json.dumps(data)}\n\n".encode('utf-8')

def create_chat_completion_chunk(
    request_id: str,
    model: str,
    content: Optional[str] = None,
    finish_reason: Optional[str] = None,
    role: Optional[str] = None
) -> Dict[str, Any]:
    delta: Dict[str, Any] = {}
    if role is not None:
        delta["role"] = role
    if content is not None:
        delta["content"] = content

    return {
        "id": request_id,
        "object": "chat.completion.chunk",
        "created": int(time.time()),
        "model": model,
        "choices": [
            {
                "index": 0,
                "delta": delta,
                "finish_reason": finish_reason
            }
        ]
    }
```

### `docker-compose.yml`

```yaml
# docker-compose.yml
services:
  nginx:
    image: nginx:latest
    container_name: notion-2api-nginx
    restart: always
    ports:
      - "${NGINX_PORT:-8088}:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - app
    networks:
      - notion-net

  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: notion-2api-app
    restart: unless-stopped
    env_file:
      - .env
    networks:
      - notion-net

networks:
  notion-net:
    driver: bridge
```

### `Dockerfile`

```dockerfile
# ====================================================================
# Dockerfile for inception-2api (v4.0 - Cloudscraper Edition)
# ====================================================================

FROM python:3.10-slim

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
WORKDIR /app

# å®‰è£… Python ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¹¶åˆ‡æ¢åˆ°é root ç”¨æˆ·
RUN useradd --create-home appuser && \
    chown -R appuser:appuser /app
USER appuser

# æš´éœ²ç«¯å£å¹¶å¯åŠ¨
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

### `main.py`

```python
# main.py
import logging
from contextlib import asynccontextmanager
from typing import Optional

from fastapi import FastAPI, Request, HTTPException, Depends, Header
from fastapi.responses import JSONResponse, StreamingResponse

from app.core.config import settings
from app.providers.notion_provider import NotionAIProvider

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

provider = NotionAIProvider()

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info(f"åº”ç”¨å¯åŠ¨ä¸­... {settings.APP_NAME} v{settings.APP_VERSION}")
    logger.info("æœåŠ¡å·²é…ç½®ä¸º Notion AI ä»£ç†æ¨¡å¼ã€‚")
    logger.info(f"æœåŠ¡å°†åœ¨ http://localhost:{settings.NGINX_PORT} ä¸Šå¯ç”¨")
    yield
    logger.info("åº”ç”¨å…³é—­ã€‚")

app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    description=settings.DESCRIPTION,
    lifespan=lifespan
)

async def verify_api_key(authorization: Optional[str] = Header(None)):
    if settings.API_MASTER_KEY and settings.API_MASTER_KEY != "1":
        if not authorization or "bearer" not in authorization.lower():
            raise HTTPException(status_code=401, detail="éœ€è¦ Bearer Token è®¤è¯ã€‚")
        token = authorization.split(" ")[-1]
        if token != settings.API_MASTER_KEY:
            raise HTTPException(status_code=403, detail="æ— æ•ˆçš„ API Keyã€‚")

@app.post("/v1/chat/completions", dependencies=[Depends(verify_api_key)])
async def chat_completions(request: Request) -> StreamingResponse:
    try:
        request_data = await request.json()
        return await provider.chat_completion(request_data)
    except Exception as e:
        logger.error(f"å¤„ç†èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}")

@app.get("/v1/models", dependencies=[Depends(verify_api_key)], response_class=JSONResponse)
async def list_models():
    return await provider.get_models()

@app.get("/", summary="æ ¹è·¯å¾„")
def root():
    return {"message": f"æ¬¢è¿æ¥åˆ° {settings.APP_NAME} v{settings.APP_VERSION}. æœåŠ¡è¿è¡Œæ­£å¸¸ã€‚"}
```

### `nginx.conf`

```ini
worker_processes auto;

events {
    worker_connections 1024;
}

http {
    upstream notion_backend {
        server app:8000;
    }

    server {
        listen 80;
        server_name localhost;

        location / {
            proxy_pass http://notion_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # ã€æ ¸å¿ƒä¿®æ­£ã€‘å¢åŠ ä»£ç†è¶…æ—¶æ—¶é—´ï¼Œä»¥åº”å¯¹CloudflareæŒ‘æˆ˜
            proxy_connect_timeout 600s;
            proxy_send_timeout 600s;
            proxy_read_timeout 600s;
            send_timeout 600s;
            
            # æµå¼ä¼ è¾“ä¼˜åŒ–
            proxy_buffering off;
            proxy_cache off;
            proxy_set_header Connection '';
            proxy_http_version 1.1;
            chunked_transfer_encoding off;
        }
    }
}
```

### `project_to_md_gui.py`

```python
#!/usr/bin/env python3
"""
é¡¹ç›®æºç  â†’ Markdown å¯¼å‡ºå™¨ (PySide6 + Material Design)
é€‰æ‹©æ–‡ä»¶å¤¹ï¼Œä¸€é”®ç”Ÿæˆ Markdownï¼Œè‡ªåŠ¨å¤åˆ¶åˆ°å‰ªè´´æ¿
"""

import sys
from pathlib import Path
from datetime import datetime

from PySide6.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
    QPushButton, QLabel, QLineEdit, QFileDialog, QProgressBar, QMessageBox
)
from PySide6.QtCore import Qt, QThread, Signal
from PySide6.QtGui import QFont

# Material Design ä¸»é¢˜
try:
    from qt_material import apply_stylesheet
    HAS_MATERIAL = True
except ImportError:
    HAS_MATERIAL = False
    print("æç¤º: æœªå®‰è£… qt-materialï¼Œè¿è¡Œ pip install qt-material å®‰è£…")


# ==================== é…ç½® ====================

INCLUDE_EXTENSIONS = {
    '.py', '.java', '.kt', '.kts', '.scala', '.go', '.rs', '.rb', '.php',
    '.cs', '.fs', '.swift', '.dart', '.lua', '.pl', '.pm', '.r',
    '.c', '.cpp', '.cc', '.cxx', '.h', '.hpp', '.hxx',
    '.js', '.ts', '.jsx', '.tsx', '.mjs', '.cjs',
    '.vue', '.svelte', '.astro',
    '.html', '.css', '.scss', '.sass', '.less', '.styl',
    '.pug', '.ejs', '.hbs', '.j2', '.jinja2',
    '.json', '.yaml', '.yml', '.toml', '.ini', '.env',
    '.xml', '.cfg', '.conf', '.properties',
    '.dockerfile', '.tf', '.hcl', '.nix',
    '.sh', '.bash', '.zsh', '.ps1', '.bat', '.cmd',
    '.gradle', '.cmake',
    '.sql', '.graphql', '.gql', '.proto',
    '.md', '.txt', '.rst',
}

INCLUDE_FILENAMES = {
    'Makefile', 'Dockerfile', 'Jenkinsfile', 'Vagrantfile',
    '.gitignore', '.dockerignore', '.env.example',
    'requirements.txt', 'setup.py', 'pyproject.toml',
    'package.json', 'tsconfig.json', 'vite.config.js',
    'Cargo.toml', 'go.mod', 'go.sum',
}

EXCLUDE_DIRS = {
    '.git', '__pycache__', 'node_modules', '.venv', 'venv', 'env',
    '.idea', '.vscode', '.vs', 'dist', 'build', 'out', 'target',
    '.next', '.nuxt', '.cache', '.parcel-cache',
    'egg-info', '.eggs', '.tox', '.pytest_cache', '.mypy_cache', '.ruff_cache',
    'coverage', '.coverage', 'htmlcov', 'bin', 'obj',
}

MAX_FILE_SIZE = 100 * 1024  # 100KB


# ==================== æ ¸å¿ƒé€»è¾‘ ====================

def get_language(filename: str) -> str:
    ext = Path(filename).suffix.lower()
    name = Path(filename).name.lower()
    
    name_map = {'dockerfile': 'dockerfile', 'makefile': 'makefile', 'jenkinsfile': 'groovy', 'vagrantfile': 'ruby'}
    if name in name_map:
        return name_map[name]
    
    ext_map = {
        '.py': 'python', '.js': 'javascript', '.mjs': 'javascript', '.cjs': 'javascript',
        '.ts': 'typescript', '.jsx': 'jsx', '.tsx': 'tsx',
        '.vue': 'vue', '.svelte': 'svelte', '.astro': 'astro',
        '.java': 'java', '.kt': 'kotlin', '.kts': 'kotlin', '.scala': 'scala',
        '.go': 'go', '.rs': 'rust', '.rb': 'ruby', '.php': 'php',
        '.cs': 'csharp', '.fs': 'fsharp', '.swift': 'swift', '.dart': 'dart',
        '.lua': 'lua', '.pl': 'perl', '.pm': 'perl', '.r': 'r',
        '.c': 'c', '.h': 'c', '.cpp': 'cpp', '.cc': 'cpp', '.cxx': 'cpp', '.hpp': 'cpp', '.hxx': 'cpp',
        '.css': 'css', '.scss': 'scss', '.sass': 'sass', '.less': 'less', '.styl': 'stylus',
        '.html': 'html', '.pug': 'pug', '.ejs': 'ejs', '.hbs': 'handlebars',
        '.j2': 'jinja2', '.jinja2': 'jinja2', '.xml': 'xml',
        '.json': 'json', '.yaml': 'yaml', '.yml': 'yaml', '.toml': 'toml',
        '.ini': 'ini', '.cfg': 'ini', '.conf': 'ini', '.properties': 'properties',
        '.env': 'bash', '.sh': 'bash', '.bash': 'bash', '.zsh': 'zsh',
        '.ps1': 'powershell', '.bat': 'batch', '.cmd': 'batch',
        '.sql': 'sql', '.graphql': 'graphql', '.gql': 'graphql', '.proto': 'protobuf',
        '.tf': 'hcl', '.hcl': 'hcl', '.nix': 'nix',
        '.gradle': 'gradle', '.cmake': 'cmake',
        '.md': 'markdown', '.rst': 'rst', '.txt': 'text', '.dockerfile': 'dockerfile',
    }
    return ext_map.get(ext, '')


def should_include(path: Path) -> bool:
    return path.name in INCLUDE_FILENAMES or path.suffix.lower() in INCLUDE_EXTENSIONS


def generate_tree(root: Path, prefix: str = '') -> list[str]:
    lines = []
    try:
        items = sorted(root.iterdir(), key=lambda x: (x.is_file(), x.name.lower()))
    except PermissionError:
        return lines
    
    visible = [i for i in items if (i.is_dir() and i.name not in EXCLUDE_DIRS) or (i.is_file() and should_include(i))]
    
    for i, item in enumerate(visible):
        is_last = i == len(visible) - 1
        conn = 'â””â”€â”€ ' if is_last else 'â”œâ”€â”€ '
        if item.is_dir():
            lines.append(f'{prefix}{conn}{item.name}/')
            lines.extend(generate_tree(item, prefix + ('    ' if is_last else 'â”‚   ')))
        else:
            lines.append(f'{prefix}{conn}{item.name}')
    return lines


def collect_files(root: Path, progress_cb=None) -> list[tuple[Path, str]]:
    files = []
    all_files = list(root.rglob('*'))
    total = len(all_files)
    
    for idx, item in enumerate(sorted(all_files)):
        if progress_cb:
            progress_cb(idx + 1, total)
        if item.is_dir():
            continue
        if any(ex in item.parts for ex in EXCLUDE_DIRS):
            continue
        if not should_include(item):
            continue
        try:
            if item.stat().st_size > MAX_FILE_SIZE:
                continue
            content = item.read_text(encoding='utf-8')
            files.append((item.relative_to(root), content))
        except (UnicodeDecodeError, PermissionError, OSError):
            continue
    return files


def generate_markdown(project_path: Path, progress_cb=None) -> str:
    name = project_path.name
    lines = [
        f'# ğŸ“ {name} æºç å¯¼å‡º', '',
        f'> å¯¼å‡ºæ—¶é—´ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}',
        f'> é¡¹ç›®è·¯å¾„ï¼š`{project_path}`',
        '', '---', '', '## ğŸ“‚ é¡¹ç›®ç»“æ„', '', '```', f'{name}/',
    ]
    lines.extend(generate_tree(project_path))
    lines.extend(['```', '', '---', '', '## ğŸ“„ æºç æ–‡ä»¶', ''])
    
    files = collect_files(project_path, progress_cb)
    for rel_path, content in files:
        lang = get_language(str(rel_path))
        lines.extend([f'### `{rel_path}`', '', f'```{lang}', content.rstrip(), '```', ''])
    
    lines.extend(['---', '', '## ğŸ“Š ç»Ÿè®¡', '', f'- æ–‡ä»¶æ•°é‡ï¼š{len(files)}'])
    total_lines = sum(c.count('\n') + 1 for _, c in files)
    total_chars = sum(len(c) for _, c in files)
    lines.append(f'- æ€»è¡Œæ•°ï¼š{total_lines:,}')
    lines.append(f'- æ€»å­—ç¬¦æ•°ï¼š{total_chars:,}')
    return '\n'.join(lines)


# ==================== åå°çº¿ç¨‹ ====================

class ExportWorker(QThread):
    progress = Signal(int, int)
    finished = Signal(bool, str, int)  # success, message, char_count
    
    def __init__(self, project_path: Path, save_path: str = None):
        super().__init__()
        self.project_path = project_path
        self.save_path = save_path
        self.markdown = ""
    
    def run(self):
        try:
            self.markdown = generate_markdown(
                self.project_path,
                lambda cur, tot: self.progress.emit(cur, tot)
            )
            if self.save_path:
                Path(self.save_path).write_text(self.markdown, encoding='utf-8')
                self.finished.emit(True, f"å·²ä¿å­˜åˆ°ï¼š\n{self.save_path}", len(self.markdown))
            else:
                self.finished.emit(True, "", len(self.markdown))
        except Exception as e:
            self.finished.emit(False, str(e), 0)


# ==================== GUI ====================

class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("ğŸ“¦ é¡¹ç›®æºç å¯¼å‡ºå™¨")
        self.setFixedSize(520, 380)
        self.worker = None
        
        central = QWidget()
        self.setCentralWidget(central)
        layout = QVBoxLayout(central)
        layout.setContentsMargins(30, 30, 30, 30)
        layout.setSpacing(15)
        
        title = QLabel("é¡¹ç›®æºç  â†’ Markdown å¯¼å‡ºå™¨")
        title.setFont(QFont("Microsoft YaHei", 16, QFont.Bold))
        title.setAlignment(Qt.AlignCenter)
        layout.addWidget(title)
        
        desc = QLabel("é€‰æ‹©é¡¹ç›®æ–‡ä»¶å¤¹ï¼Œç”ŸæˆåŒ…å«æ‰€æœ‰æºç çš„ Markdown æ–‡ä»¶")
        desc.setAlignment(Qt.AlignCenter)
        desc.setStyleSheet("color: gray;")
        layout.addWidget(desc)
        
        layout.addSpacing(10)
        
        path_layout = QHBoxLayout()
        self.path_input = QLineEdit()
        self.path_input.setPlaceholderText("è¯·é€‰æ‹©é¡¹ç›®æ–‡ä»¶å¤¹...")
        path_layout.addWidget(self.path_input)
        
        browse_btn = QPushButton("æµè§ˆ...")
        browse_btn.clicked.connect(self.browse_folder)
        browse_btn.setFixedWidth(80)
        path_layout.addWidget(browse_btn)
        layout.addLayout(path_layout)
        
        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        self.progress_bar.setValue(0)
        layout.addWidget(self.progress_bar)
        
        self.status_label = QLabel("è¯·é€‰æ‹©é¡¹ç›®æ–‡ä»¶å¤¹")
        self.status_label.setAlignment(Qt.AlignCenter)
        self.status_label.setStyleSheet("color: gray;")
        layout.addWidget(self.status_label)
        
        layout.addSpacing(10)
        
        btn_layout = QHBoxLayout()
        btn_layout.addStretch()
        
        self.clipboard_btn = QPushButton("ğŸ“‹ ç”Ÿæˆå¹¶å¤åˆ¶åˆ°å‰ªè´´æ¿")
        self.clipboard_btn.clicked.connect(self.export_to_clipboard)
        self.clipboard_btn.setFixedHeight(36)
        btn_layout.addWidget(self.clipboard_btn)
        
        self.save_btn = QPushButton("ğŸ’¾ ç”Ÿæˆå¹¶ä¿å­˜æ–‡ä»¶")
        self.save_btn.clicked.connect(self.export_to_file)
        self.save_btn.setFixedHeight(36)
        btn_layout.addWidget(self.save_btn)
        
        btn_layout.addStretch()
        layout.addLayout(btn_layout)
        layout.addStretch()
    
    def browse_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "é€‰æ‹©é¡¹ç›®æ–‡ä»¶å¤¹")
        if folder:
            self.path_input.setText(folder)
            self.status_label.setText(f"å·²é€‰æ‹©ï¼š{Path(folder).name}")
    
    def export_to_clipboard(self):
        self._start_export(to_clipboard=True)
    
    def export_to_file(self):
        self._start_export(to_clipboard=False)
    
    def _start_export(self, to_clipboard=True):
        path = self.path_input.text()
        if not path:
            QMessageBox.warning(self, "æç¤º", "è¯·å…ˆé€‰æ‹©é¡¹ç›®æ–‡ä»¶å¤¹")
            return
        
        project_path = Path(path)
        if not project_path.exists() or not project_path.is_dir():
            QMessageBox.critical(self, "é”™è¯¯", "é€‰æ‹©çš„è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸æ˜¯æ–‡ä»¶å¤¹")
            return
        
        save_path = None
        if not to_clipboard:
            save_path, _ = QFileDialog.getSaveFileName(
                self, "ä¿å­˜æ–‡ä»¶", f"{project_path.name}_source.md",
                "Markdown (*.md);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
            )
            if not save_path:
                return
        
        self.clipboard_btn.setEnabled(False)
        self.save_btn.setEnabled(False)
        self.status_label.setText("æ­£åœ¨æ‰«ææ–‡ä»¶...")
        self.progress_bar.setValue(0)
        
        self.worker = ExportWorker(project_path, save_path)
        self.worker.progress.connect(self._on_progress)
        self.worker.finished.connect(lambda ok, msg, cnt: self._on_finished(ok, msg, cnt, to_clipboard))
        self.worker.start()
    
    def _on_progress(self, current, total):
        if total > 0:
            self.progress_bar.setValue(int(current / total * 100))
    
    def _on_finished(self, success, message, char_count, to_clipboard):
        self.clipboard_btn.setEnabled(True)
        self.save_btn.setEnabled(True)
        self.progress_bar.setValue(100)
        
        if success:
            if to_clipboard and self.worker:
                QApplication.clipboard().setText(self.worker.markdown)
                QMessageBox.information(
                    self, "å®Œæˆ",
                    f"å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼\n\nå­—ç¬¦æ•°ï¼š{char_count:,}\n\nç°åœ¨å¯ä»¥ç²˜è´´åˆ° Notion é¡µé¢æˆ–èŠå¤©çª—å£ã€‚"
                )
            elif message:
                QMessageBox.information(self, "å®Œæˆ", message)
            self.status_label.setText("å®Œæˆï¼")
        else:
            QMessageBox.critical(self, "é”™è¯¯", f"å¯¼å‡ºå¤±è´¥ï¼š{message}")
            self.status_label.setText("å¯¼å‡ºå¤±è´¥")


def main():
    app = QApplication(sys.argv)
    if HAS_MATERIAL:
        apply_stylesheet(app, theme='dark_teal.xml')
    window = MainWindow()
    window.show()
    sys.exit(app.exec())


if __name__ == '__main__':
    main()
```

### `README.md`

```markdown
# ğŸš€ notion-2api: å°† Notion AI è½¬æ¢ä¸ºç§æœ‰ OpenAI API

![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)
![Stars](https://img.shields.io/github/stars/lzA6/notion-2api?style=social)
![Issues](https://img.shields.io/github/issues/lzA6/notion-2api)
![Forks](https://img.shields.io/github/forks/lzA6/notion-2api)

> "æˆ‘ä»¬å¹¶éåœ¨åˆ›é€ å·¥å…·ï¼Œè€Œæ˜¯åœ¨å»¶ä¼¸è‡ªæˆ‘ã€‚æ¯ä¸€æ¬¡ä»£ç çš„æ•²å‡»ï¼Œéƒ½æ˜¯å¯¹ä¸–ç•Œçš„ä¸€æ¬¡æ¸©æŸ”çš„é‡å¡‘ã€‚" â€”â€” lzA6 (AI æ„æƒ³)

æ¬¢è¿æ¥åˆ° `notion-2api` çš„ä¸–ç•Œï¼è¿™æ˜¯ä¸€ä¸ªèƒ½å°†ä½ å¼ºå¤§çš„ Notion AI ä½“éªŒï¼Œæ— ç¼è½¬æ¢ä¸ºå…¼å®¹ OpenAI æ ¼å¼çš„ API æœåŠ¡çš„ç¥å¥‡é¡¹ç›®ã€‚è¿™æ„å‘³ç€ï¼Œä½ å¯ä»¥å°† Notion AI ä½œä¸ºåç«¯ï¼Œé©±åŠ¨ä»»ä½•æ”¯æŒ OpenAI API çš„åº”ç”¨ç¨‹åºã€è„šæœ¬æˆ–æœåŠ¡ã€‚

**English Readme Coming Soon!**

---

## ğŸ“‹ ç›®å½•

- [âœ¨ é¡¹ç›®äº®ç‚¹](#-é¡¹ç›®äº®ç‚¹)
- [ğŸ“‚ é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„)
- [ğŸ¤” å·¥ä½œåŸç†](#-å·¥ä½œåŸç†)
- [ğŸ› ï¸ æŠ€æœ¯æ ˆ](#ï¸-æŠ€æœ¯æ ˆ)
- [ğŸ“– ä½¿ç”¨æ•™ç¨‹](#-ä½¿ç”¨æ•™ç¨‹)
- [ğŸ”— ä¸€é”®éƒ¨ç½²](#-ä¸€é”®éƒ¨ç½²-è§„åˆ’ä¸­)
- [ğŸ§  æºç è§£æ](#-æºç è§£æ)
- [ğŸ“Š é¡¹ç›®è¯„ä¼°](#-é¡¹ç›®è¯„ä¼°)
- [ğŸ—ºï¸ æœªæ¥è§„åˆ’](#ï¸-æœªæ¥è§„åˆ’)
- [ğŸ¤– AI å¼€å‘è€…æŒ‡å—](#-ai-å¼€å‘è€…æŒ‡å—)
- [ğŸ’– è´¡çŒ®æŒ‡å—](#-è´¡çŒ®æŒ‡å—)

---

## âœ¨ é¡¹ç›®äº®ç‚¹

- **æ— ç¼è½¬æ¢**: å°† Notion AI çš„éå®˜æ–¹æ¥å£å®Œç¾ä¼ªè£…æˆæ ‡å‡†çš„ OpenAI `v1/chat/completions` æ¥å£
- **å¤šæ¨¡å‹æ”¯æŒ**: æ”¯æŒ Notion AI åç«¯çš„æ‰€æœ‰å¯ç”¨æ¨¡å‹ï¼ˆä»¥ Notion å®é™…æä¾›ä¸ºå‡†ï¼‰
- **æµå¼å“åº”**: å®Œå…¨æ”¯æŒ `stream=true`ï¼Œæä¾›æµç•…çš„æ‰“å­—æœºä½“éªŒ
- **Docker åŒ–éƒ¨ç½²**: ä¸€è¡Œå‘½ä»¤è½»æ¾å¯åŠ¨ï¼Œå‘Šåˆ«ç¹çç¯å¢ƒé…ç½®
- **é«˜æ€§èƒ½**: åŸºäº FastAPI å’Œ Uvicornï¼Œæä¾›ç¨³å®šé«˜æ•ˆçš„å¼‚æ­¥å¤„ç†èƒ½åŠ›
- **æ™ºèƒ½åçˆ¬**: å†…ç½® `cloudscraper`ï¼Œç»•è¿‡ Cloudflare é˜²æŠ¤ï¼Œæé«˜è¯·æ±‚æˆåŠŸç‡
- **çµæ´»é…ç½®**: é€šè¿‡ç®€å•çš„ `.env` æ–‡ä»¶ç®¡ç†æ‰€æœ‰å‡­è¯å’Œé…ç½®

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
notion-2api/
â”œâ”€â”€ .env                    # ç¯å¢ƒé…ç½®æ–‡ä»¶ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
â”œâ”€â”€ .env.example            # ç¯å¢ƒé…ç½®æ¨¡æ¿
â”œâ”€â”€ Dockerfile              # Docker é•œåƒæ„å»ºæ–‡ä»¶
â”œâ”€â”€ docker-compose.yml      # Docker Compose ç¼–æ’æ–‡ä»¶
â”œâ”€â”€ main.py                 # FastAPI åº”ç”¨ä¸»å…¥å£
â”œâ”€â”€ nginx.conf              # Nginx åå‘ä»£ç†é…ç½®
â”œâ”€â”€ requirements.txt        # Python ä¾èµ–åˆ—è¡¨
â””â”€â”€ app/
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ config.py       # Pydantic é…ç½®æ¨¡å‹
    â”œâ”€â”€ providers/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ base_provider.py # æŠ½è±¡åŸºç±»
    â”‚   â””â”€â”€ notion_provider.py # Notion API äº¤äº’æ ¸å¿ƒ
    â””â”€â”€ utils/
        â””â”€â”€ sse_utils.py    # Server-Sent Events å·¥å…·
```

---

## ğŸ¤” å·¥ä½œåŸç†

`notion-2api` å……å½“äº† OpenAI API å’Œ Notion AI ä¹‹é—´çš„ç¿»è¯‘å®˜ï¼Œå°†ä¸¤ç§ä¸åŒçš„åè®®è¿›è¡Œæ— ç¼è½¬æ¢ã€‚

### æ¶æ„æµç¨‹å›¾

```mermaid
graph TD
    A[å®¢æˆ·ç«¯åº”ç”¨] --> B[Nginx åå‘ä»£ç†]
    B --> C[FastAPI åº”ç”¨]
    C --> D[è®¤è¯ä¸­é—´ä»¶]
    D --> E[Notion Provider]
    E --> F[Cloudscraper]
    F --> G[Notion AI API]
    G --> H[NDJSON æµè§£æ]
    H --> I[SSE æ ¼å¼è½¬æ¢]
    I --> C
    C --> B
    B --> A
```

### æ•°æ®æµè¯¦è§£

1. **è¯·æ±‚æ¥æ”¶**: å®¢æˆ·ç«¯å‘é€æ ‡å‡†çš„ OpenAI API æ ¼å¼è¯·æ±‚
2. **åè®®è½¬æ¢**: FastAPI å°†è¯·æ±‚è½¬æ¢ä¸º Notion AI èƒ½ç†è§£çš„æ ¼å¼
3. **ä¼šè¯ç®¡ç†**: åˆ›å»º Notion å¯¹è¯çº¿ç¨‹å¹¶ç»´æŒä¼šè¯çŠ¶æ€
4. **æµå¼å¤„ç†**: å®æ—¶è§£æ Notion è¿”å›çš„ NDJSON æ•°æ®æµ
5. **æ ¼å¼è½¬æ¢**: å°†è§£æåçš„æ•°æ®è½¬æ¢ä¸º OpenAI å…¼å®¹çš„ SSE æ ¼å¼
6. **å“åº”è¿”å›**: é€šè¿‡æµå¼å“åº”å°†æ•°æ®å®æ—¶è¿”å›ç»™å®¢æˆ·ç«¯

---

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

| æŠ€æœ¯ç»„ä»¶ | ç‰ˆæœ¬/ç±»å‹ | ç”¨é€”è¯´æ˜ |
|---------|-----------|----------|
| **FastAPI** | 0.104+ | ç°ä»£åŒ–å¼‚æ­¥ Web æ¡†æ¶ï¼Œæä¾›é«˜æ€§èƒ½ API æœåŠ¡ |
| **Uvicorn** | 0.24+ | ASGI æœåŠ¡å™¨ï¼Œç”¨äºè¿è¡Œ FastAPI åº”ç”¨ |
| **Cloudscraper** | æœ€æ–°ç‰ˆ | ç»•è¿‡ Cloudflare é˜²æŠ¤ï¼Œç¡®ä¿ç¨³å®šè¿æ¥ |
| **Pydantic** | 2.0+ | æ•°æ®éªŒè¯å’Œè®¾ç½®ç®¡ç† |
| **Docker** | æœ€æ–°ç‰ˆ | å®¹å™¨åŒ–éƒ¨ç½²å’Œç¯å¢ƒéš”ç¦» |
| **Nginx** | æœ€æ–°ç‰ˆ | åå‘ä»£ç†å’Œè´Ÿè½½å‡è¡¡ |
| **Python** | 3.8+ | ä¸»è¦ç¼–ç¨‹è¯­è¨€ |

---

## ğŸ“– ä½¿ç”¨æ•™ç¨‹

### ç¯å¢ƒå‡†å¤‡

1. **å®‰è£… Docker**: è®¿é—® [Docker å®˜ç½‘](https://www.docker.com/get-started) ä¸‹è½½å¹¶å®‰è£…
2. **å®‰è£… Git**: ç”¨äºå…‹éš†ä»£ç ä»“åº“

### è·å– Notion å‡­è¯

è¿™æ˜¯æœ€å…³é”®çš„ä¸€æ­¥ï¼Œè¯·ä»”ç»†æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

#### è·å– token_v2

1. ç™»å½• [Notion](https://www.notion.so/)
2. æ‰“å¼€æµè§ˆå™¨å¼€å‘è€…å·¥å…· (F12)
3. åˆ‡æ¢åˆ° **Application** æ ‡ç­¾é¡µ
4. å±•å¼€ **Cookies** â†’ **https://www.notion.so**
5. æ‰¾åˆ° `token_v2` é¡¹ï¼Œå¤åˆ¶å…¶ **Value**

#### è·å– Space ID å’Œ User ID

1. åœ¨å¼€å‘è€…å·¥å…·ä¸­åˆ‡æ¢åˆ° **Network** æ ‡ç­¾é¡µ
2. åœ¨ Notion ä¸­è¿›è¡Œä»»æ„æ“ä½œï¼ˆå¦‚ç‚¹å‡»é¡µé¢ï¼‰
3. æ‰¾åˆ° `getRecordValues` æˆ–ç±»ä¼¼è¯·æ±‚
4. æŸ¥çœ‹è¯·æ±‚å¤´ä¸­çš„ï¼š
   - `x-notion-active-user-header` â†’ **User ID**
   - `x-notion-space-id` â†’ **Space ID**

### é…ç½®ç¯å¢ƒå˜é‡

1. **å…‹éš†é¡¹ç›®**:
   ```bash
   git clone https://github.com/lzA6/notion-2api.git
   cd notion-2api
   ```

2. **åˆ›å»ºé…ç½®æ–‡ä»¶**:
   ```bash
   cp .env.example .env
   ```

3. **ç¼–è¾‘ `.env` æ–‡ä»¶**:
   ```env
   # å®‰å…¨é…ç½®ï¼ˆå¯é€‰ï¼‰
   API_MASTER_KEY=your_secret_key_here
   
   # éƒ¨ç½²é…ç½®
   NGINX_PORT=8088
   
   # Notion å‡­è¯ï¼ˆå¿…éœ€ï¼‰
   NOTION_COOKIE="ä½ çš„token_v2å€¼"
   NOTION_SPACE_ID="ä½ çš„Space ID"
   NOTION_USER_ID="ä½ çš„User ID"
   NOTION_USER_NAME="ä½ çš„åå­—"
   NOTION_USER_EMAIL="your_email@example.com"
   ```

### å¯åŠ¨æœåŠ¡

```bash
docker-compose up -d --build
```

### æµ‹è¯• API

```bash
curl http://localhost:8088/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your_secret_key_here" \
  -d '{
    "model": "claude-sonnet-4.5",
    "messages": [{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}],
    "stream": true
  }'
```

å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œä½ å°†çœ‹åˆ°æ¥è‡ª Notion AI çš„æµå¼å“åº”ï¼

---

## ğŸ§  æºç è§£æ

### æ ¸å¿ƒæ¨¡å—æ¶æ„

```mermaid
graph TB
    A[main.py] --> B[Config Manager]
    A --> C[Auth Middleware]
    A --> D[Route Handlers]
    D --> E[Notion Provider]
    E --> F[Session Management]
    E --> G[Stream Parser]
    E --> H[Response Formatter]
    G --> I[NDJSON Parser]
    H --> J[SSE Generator]
```

### `main.py` - åº”ç”¨å…¥å£

è´Ÿè´£åˆå§‹åŒ– FastAPI åº”ç”¨ã€é…ç½®ä¸­é—´ä»¶å’Œè·¯ç”±ï¼š

```python
@app.post("/v1/chat/completions")
async def chat_completions(
    request: ChatCompletionRequest,
    auth: bool = Depends(verify_api_key)
):
    """å¤„ç†èŠå¤©è¡¥å…¨è¯·æ±‚ï¼Œæ”¯æŒæµå¼å’Œéæµå¼å“åº”"""
```

### `app/core/config.py` - é…ç½®ç®¡ç†

ä½¿ç”¨ Pydantic è¿›è¡Œç±»å‹å®‰å…¨çš„é…ç½®ç®¡ç†ï¼š

```python
class Settings(BaseSettings):
    """åº”ç”¨é…ç½®æ¨¡å‹ï¼Œè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡åŠ è½½"""
    API_MASTER_KEY: str = "1"
    NGINX_PORT: int = 8088
    NOTION_COOKIE: str
    NOTION_SPACE_ID: str
    NOTION_USER_ID: str
```

### `app/providers/notion_provider.py` - æ ¸å¿ƒé€»è¾‘

å®ç°ä¸ Notion AI çš„äº¤äº’ï¼š

- **ä¼šè¯é¢„çƒ­**: åˆå§‹åŒ–æ—¶è®¿é—® Notion ä»¥è·å–æœ‰æ•ˆ Cookie
- **çº¿ç¨‹ç®¡ç†**: ä¸ºæ¯ä¸ªå¯¹è¯åˆ›å»ºç‹¬ç«‹çš„ Notion çº¿ç¨‹
- **æµå¼è§£æ**: å®æ—¶è§£æ Notion çš„ NDJSON å“åº”æµ
- **æ•°æ®æ¸…æ´—**: æ¸…ç†å“åº”ä¸­çš„å†—ä½™ä¿¡æ¯å’Œæ ¼å¼æ ‡è®°

### `app/utils/sse_utils.py` - æµå¼å“åº”

å°†æ•°æ®è½¬æ¢ä¸º Server-Sent Events æ ¼å¼ï¼š

```python
def create_sse_data(data: dict) -> str:
    """å°†æ•°æ®è½¬æ¢ä¸º SSE æ ¼å¼"""
    return f"data: {json.dumps(data)}\n\n"
```

---

## ğŸ“Š é¡¹ç›®è¯„ä¼°

### âœ… å·²å®ŒæˆåŠŸèƒ½

- [x] æ ¸å¿ƒä»£ç†åŠŸèƒ½ - OpenAI API åˆ° Notion AI çš„åè®®è½¬æ¢
- [x] å®Œæ•´çš„æµå¼å“åº”æ”¯æŒ
- [x] Docker å®¹å™¨åŒ–éƒ¨ç½²
- [x] Cloudflare é˜²æŠ¤ç»•è¿‡
- [x] å¤šæ¨¡å‹æ”¯æŒï¼ˆClaudeã€GPTã€Geminiï¼‰
- [x] API å¯†é’¥è®¤è¯
- [x] ç¯å¢ƒé…ç½®ç®¡ç†

### ğŸŒŸ æ ¸å¿ƒä¼˜åŠ¿

1. **ç”Ÿæ€å…¼å®¹æ€§**: æ— ç¼æ¥å…¥ç°æœ‰ OpenAI ç”Ÿæ€å·¥å…·
2. **æˆæœ¬æ•ˆç›Š**: åˆ©ç”¨ç°æœ‰ Notion è®¢é˜…ï¼Œæ— éœ€é¢å¤–ä»˜è´¹
3. **éšç§ä¿æŠ¤**: ç§æœ‰åŒ–éƒ¨ç½²ï¼Œæ•°æ®å®Œå…¨è‡ªä¸»æ§åˆ¶
4. **æŠ€æœ¯ä»·å€¼**: å­¦ä¹ ç°ä»£ Web å¼€å‘å’Œ API è®¾è®¡çš„ä¼˜ç§€èŒƒä¾‹

### âš ï¸ é™åˆ¶ä¸æŒ‘æˆ˜

1. **API ç¨³å®šæ€§**: ä¾èµ– Notion éå®˜æ–¹æ¥å£ï¼Œå­˜åœ¨å˜æ›´é£é™©
2. **å‡­è¯ç»´æŠ¤**: `token_v2` ä¼šè¿‡æœŸï¼Œéœ€è¦å®šæœŸæ›´æ–°
3. **é˜²æŠ¤å¯¹æŠ—**: Cloudflare ç­–ç•¥æ›´æ–°å¯èƒ½å¯¼è‡´è¿æ¥å¤±è´¥
4. **åŠŸèƒ½å±€é™**: ç›®å‰ä¸»è¦æ”¯æŒèŠå¤©è¡¥å…¨åŠŸèƒ½

---

## ğŸ—ºï¸ æœªæ¥è§„åˆ’

### ğŸ¯ çŸ­æœŸç›®æ ‡

- [ ] æ”¯æŒéæµå¼å“åº” (`stream=false`)
- [ ] å¢å¼ºé”™è¯¯å¤„ç†å’Œç”¨æˆ·åé¦ˆ
- [ ] æ”¹è¿› token è‡ªåŠ¨åˆ·æ–°æœºåˆ¶
- [ ] åŠ¨æ€æ¨¡å‹åˆ—è¡¨è·å–
- [ ] æ›´è¯¦ç»†çš„è¿è¡Œæ—¥å¿—

### ğŸ’¡ é•¿æœŸæ„¿æ™¯

- [ ] å¤šè´¦æˆ·è´Ÿè½½å‡è¡¡
- [ ] Function Calling æ”¯æŒ
- [ ] Web ç®¡ç†ç•Œé¢
- [ ] æ’ä»¶åŒ–æ¶æ„
- [ ] ä½¿ç”¨é‡ç»Ÿè®¡å’Œé™åˆ¶

---

## ğŸ¤– AI å¼€å‘è€…æŒ‡å—

### é¡¹ç›®ç†è§£è¦ç‚¹

1. **æ¶æ„æ¨¡å¼**: è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„åè®®è½¬æ¢ä»£ç†æœåŠ¡
2. **æ ¸å¿ƒæŠ€æœ¯**: å¼‚æ­¥ç¼–ç¨‹ã€æµå¼å¤„ç†ã€åçˆ¬è™«æŠ€æœ¯
3. **å…³é”®æŒ‘æˆ˜**: éå®˜æ–¹ API çš„ç¨³å®šæ€§å’Œå…¼å®¹æ€§ç»´æŠ¤
4. **æ‰©å±•æ–¹å‘**: æ›´å¤š AI æœåŠ¡çš„åè®®è½¬æ¢æ”¯æŒ

### ä»£ç è´¡çŒ®å»ºè®®

- ä¼˜å…ˆä¿®å¤ç¨³å®šæ€§ç›¸å…³é—®é¢˜
- æ”¹è¿›é”™è¯¯å¤„ç†å’Œç”¨æˆ·åé¦ˆ
- æ·»åŠ å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
- ä¼˜åŒ–æ–‡æ¡£å’Œç¤ºä¾‹ä»£ç 

---

## ğŸ’– è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ®ï¼š

- ğŸ› **é—®é¢˜åé¦ˆ**: æäº¤ [Issue](https://github.com/lzA6/notion-2api/issues)
- ğŸ”§ **ä»£ç è´¡çŒ®**: åˆ›å»º [Pull Request](https://github.com/lzA6/notion-2api/pulls)
- ğŸ’¡ **æƒ³æ³•åˆ†äº«**: å‚ä¸ [Discussions](https://github.com/lzA6/notion-2api/discussions)
- â­ **é¡¹ç›®æ”¯æŒ**: ç»™é¡¹ç›®ç‚¹èµå’Œåˆ†äº«

æ¯ä¸€ä¸ªè´¡çŒ®ï¼Œæ— è®ºå¤§å°ï¼Œéƒ½æ˜¯å¯¹å¼€æºä¸–ç•Œçš„å®è´µç¤¼ç‰©ã€‚

---

**è®©æˆ‘ä»¬ä¸€èµ·ï¼Œç”¨ä»£ç åˆ›é€ æ›´å¤šå¯èƒ½æ€§ï¼** ğŸš€
```

### `requirements.txt`

```text
# requirements.txt
fastapi
uvicorn[standard]
httpx
pydantic-settings
python-dotenv
cloudscraper
```

### `é¡¹ç›®å®Œæ•´ç»“æ„ä»£ç .txt`

```text
é¡¹ç›® 'notion-2api' çš„ç»“æ„æ ‘:
ğŸ“‚ notion-2api/
    ğŸ“„ .env
    ğŸ“„ .env.example
    ğŸ“„ Dockerfile
    ğŸ“„ docker-compose.yml
    ğŸ“„ main.py
    ğŸ“„ nginx.conf
    ğŸ“„ requirements.txt
    ğŸ“‚ app/
        ğŸ“‚ core/
            ğŸ“„ __init__.py
            ğŸ“„ config.py
        ğŸ“‚ providers/
            ğŸ“„ __init__.py
            ğŸ“„ base_provider.py
            ğŸ“„ notion_provider.py
        ğŸ“‚ utils/
            ğŸ“„ sse_utils.py
================================================================================

--- æ–‡ä»¶è·¯å¾„: .env ---

# [è‡ªåŠ¨å¡«å……] notion-2api ç”Ÿäº§ç¯å¢ƒé…ç½®

# --- å®‰å…¨é…ç½® ---
API_MASTER_KEY=1

# --- ç«¯å£é…ç½® ---
NGINX_PORT=8088

# --- Notion å‡­è¯ (ä»¥ä¸‹å‡ä¸ºå¿…é¡»æˆ–å¼ºçƒˆå»ºè®®è®¾ç½®) ---

# 1. æ‚¨çš„ token_v2 (å·²ä»æœ€æ–°æ—¥å¿—ä¸­æå–å¹¶æ›´æ–°)
NOTION_COOKIE="v03%3AeyJhbGciOiJkaXIiLCJraWQiOiJwcm9kdWN0aW9uOnRva2VuLXYzOjIwMjQtMTEtMDciLCJlbmMiOiJBMjU2Q0JDLUhTNTEyIn0..mIRgS9AYZx8rn6OUJ7F9pA.QFex5O4ZzVCLG1JCNOgbbqmYf9IyntouodTfm2wn7LbmY0Zs-akV51n3dwtaC2K3ctm9Jj91PVRsl-6k9phiTUaIO_3FtSYmEYZrmCYEXa1iWJAwdROmySSRcMeSwsswgakVanb-sal9B8IH-YACTq9SLfooARLw65pwljahMdG-jJKi5X2PwfUrENeeRGDTQF0I6SLxp0-VxzOuWn-MDPej-S40hbDQY9kDyDZ9tyaYptOsu3KEP1M6HiwD0kqqQETUdYFPbYqK8ItPdKDyrFr8zIo21zfMAwLMeSvvTda-cBm0OVnBuGvqlLA92dVYON55mts-r_U2Xmjt9g9pAwL_GG8-HW9Qo-IyiaO9oB4.D17Jn2Mp6Y62_lbuZ0Ggz0ugnej-Ue7coltqqYHI-KE"

# 2. æ‚¨çš„ Space ID (ä¿æŒä¸å˜)
NOTION_SPACE_ID="f108eefa-d0dc-8181-8382-0003e15d764e"

# 3. æ‚¨çš„ç”¨æˆ· ID (ä»æ—¥å¿—ä¸­æå–)
NOTION_USER_ID="200d872b-594c-8153-b674-00028d202a8b"

# 4. æ‚¨çš„ Notion ç”¨æˆ·å (è¯·ç¡®è®¤æ˜¯å¦å‡†ç¡®)
NOTION_USER_NAME="åˆ©ä»”"

# 5. æ‚¨çš„ Notion ç™»å½•é‚®ç®± (è¯·æ›¿æ¢ä¸ºæ‚¨çš„çœŸå®é‚®ç®±)
NOTION_USER_EMAIL="q13645947407@gmail.com"

# 6. å¯é€‰ï¼šé¡µé¢ Block ID (ä¿æŒç•™ç©ºä»¥æé«˜å…¼å®¹æ€§)
NOTION_BLOCK_ID=""

# 7. å¯é€‰ï¼šå®¢æˆ·ç«¯ç‰ˆæœ¬ (ä¿æŒé»˜è®¤å³å¯)
NOTION_CLIENT_VERSION="23.13.20251011.2037"

--- æ–‡ä»¶è·¯å¾„: .env.example ---

# ====================================================================
# notion-2api é…ç½®æ–‡ä»¶æ¨¡æ¿ (æœ€ç»ˆç‰ˆ)
# ====================================================================
#
# è¯·å°†æ­¤æ–‡ä»¶é‡å‘½åä¸º ".env" å¹¶å¡«å…¥æ‚¨çš„å‡­è¯ã€‚
#

# --- æ ¸å¿ƒå®‰å…¨é…ç½® (å¯é€‰) ---
API_MASTER_KEY=your_secret_key_here

# --- éƒ¨ç½²é…ç½® (å¯é€‰) ---
NGINX_PORT=8088

# --- Notion å‡­è¯ (ä»¥ä¸‹å‡ä¸ºå¿…é¡»æˆ–å¼ºçƒˆå»ºè®®è®¾ç½®) ---
# 1) ç²˜è´´ token_v2 çš„å€¼ æˆ– å®Œæ•´ Cookie
NOTION_COOKIE="åœ¨æ­¤å¤„ç²˜è´´ token_v2 å€¼ æˆ– å®Œæ•´ Cookie"

# 2) æ‚¨çš„ Space ID
NOTION_SPACE_ID="åœ¨æ­¤å¤„ç²˜è´´æ‚¨çš„ Space ID"

# 3) æ‚¨çš„ç”¨æˆ· ID (æµè§ˆå™¨å¼€å‘è€…å·¥å…·ä¸­ x-notion-active-user-header çš„å€¼)
NOTION_USER_ID="åœ¨æ­¤å¤„ç²˜è´´æ‚¨çš„ Notion ç”¨æˆ· ID"

# 4) æ‚¨çš„ Notion ç”¨æˆ·å (æ˜¾ç¤ºåœ¨å·¦ä¸Šè§’çš„åç§°)
NOTION_USER_NAME="åˆ©ä»”"

# 5) æ‚¨çš„ Notion ç™»å½•é‚®ç®±
NOTION_USER_EMAIL="q13645947407@gmail.com"

# å¯é€‰ï¼šæƒ³ç»‘å®šçš„é¡µé¢ blockIdã€‚ç•™ç©ºåˆ™ä¸ç»‘å®šç‰¹å®šé¡µé¢ä¸Šä¸‹æ–‡ã€‚
NOTION_BLOCK_ID=""

# å¯é€‰ï¼šæµè§ˆå™¨ä¸­çœ‹åˆ°çš„å®¢æˆ·ç«¯ç‰ˆæœ¬
NOTION_CLIENT_VERSION="23.13.20251011.2037"

--- æ–‡ä»¶è·¯å¾„: Dockerfile ---

# ====================================================================
# Dockerfile for inception-2api (v4.0 - Cloudscraper Edition)
# ====================================================================

FROM python:3.10-slim

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
WORKDIR /app

# å®‰è£… Python ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¹¶åˆ‡æ¢åˆ°é root ç”¨æˆ·
RUN useradd --create-home appuser && \
    chown -R appuser:appuser /app
USER appuser

# æš´éœ²ç«¯å£å¹¶å¯åŠ¨
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]


--- æ–‡ä»¶è·¯å¾„: docker-compose.yml ---

# docker-compose.yml
services:
  nginx:
    image: nginx:latest
    container_name: notion-2api-nginx
    restart: always
    ports:
      - "${NGINX_PORT:-8088}:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - app
    networks:
      - notion-net

  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: notion-2api-app
    restart: unless-stopped
    env_file:
      - .env
    networks:
      - notion-net

networks:
  notion-net:
    driver: bridge


--- æ–‡ä»¶è·¯å¾„: main.py ---

# main.py
import logging
from contextlib import asynccontextmanager
from typing import Optional

from fastapi import FastAPI, Request, HTTPException, Depends, Header
from fastapi.responses import JSONResponse, StreamingResponse

from app.core.config import settings
from app.providers.notion_provider import NotionAIProvider

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

provider = NotionAIProvider()

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info(f"åº”ç”¨å¯åŠ¨ä¸­... {settings.APP_NAME} v{settings.APP_VERSION}")
    logger.info("æœåŠ¡å·²é…ç½®ä¸º Notion AI ä»£ç†æ¨¡å¼ã€‚")
    logger.info(f"æœåŠ¡å°†åœ¨ http://localhost:{settings.NGINX_PORT} ä¸Šå¯ç”¨")
    yield
    logger.info("åº”ç”¨å…³é—­ã€‚")

app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    description=settings.DESCRIPTION,
    lifespan=lifespan
)

async def verify_api_key(authorization: Optional[str] = Header(None)):
    if settings.API_MASTER_KEY and settings.API_MASTER_KEY != "1":
        if not authorization or "bearer" not in authorization.lower():
            raise HTTPException(status_code=401, detail="éœ€è¦ Bearer Token è®¤è¯ã€‚")
        token = authorization.split(" ")[-1]
        if token != settings.API_MASTER_KEY:
            raise HTTPException(status_code=403, detail="æ— æ•ˆçš„ API Keyã€‚")

@app.post("/v1/chat/completions", dependencies=[Depends(verify_api_key)])
async def chat_completions(request: Request) -> StreamingResponse:
    try:
        request_data = await request.json()
        return await provider.chat_completion(request_data)
    except Exception as e:
        logger.error(f"å¤„ç†èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}")

@app.get("/v1/models", dependencies=[Depends(verify_api_key)], response_class=JSONResponse)
async def list_models():
    return await provider.get_models()

@app.get("/", summary="æ ¹è·¯å¾„")
def root():
    return {"message": f"æ¬¢è¿æ¥åˆ° {settings.APP_NAME} v{settings.APP_VERSION}. æœåŠ¡è¿è¡Œæ­£å¸¸ã€‚"}


--- æ–‡ä»¶è·¯å¾„: nginx.conf ---

worker_processes auto;

events {
    worker_connections 1024;
}

http {
    upstream notion_backend {
        server app:8000;
    }

    server {
        listen 80;
        server_name localhost;

        location / {
            proxy_pass http://notion_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # ã€æ ¸å¿ƒä¿®æ­£ã€‘å¢åŠ ä»£ç†è¶…æ—¶æ—¶é—´ï¼Œä»¥åº”å¯¹CloudflareæŒ‘æˆ˜
            proxy_connect_timeout 600s;
            proxy_send_timeout 600s;
            proxy_read_timeout 600s;
            send_timeout 600s;
            
            # æµå¼ä¼ è¾“ä¼˜åŒ–
            proxy_buffering off;
            proxy_cache off;
            proxy_set_header Connection '';
            proxy_http_version 1.1;
            chunked_transfer_encoding off;
        }
    }
}


--- æ–‡ä»¶è·¯å¾„: requirements.txt ---

# requirements.txt
fastapi
uvicorn[standard]
httpx
pydantic-settings
python-dotenv
cloudscraper


--- æ–‡ä»¶è·¯å¾„: app\core\__init__.py ---



--- æ–‡ä»¶è·¯å¾„: app\core\config.py ---

# app/core/config.py
from pydantic_settings import BaseSettings, SettingsConfigDict
from typing import List, Optional

class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding='utf-8',
        extra="ignore"
    )

    APP_NAME: str = "notion-2api"
    APP_VERSION: str = "4.0.0" # æœ€ç»ˆç¨³å®šç‰ˆ
    DESCRIPTION: str = "ä¸€ä¸ªå°† Notion AI è½¬æ¢ä¸ºå…¼å®¹ OpenAI æ ¼å¼ API çš„é«˜æ€§èƒ½ä»£ç†ã€‚"

    API_MASTER_KEY: Optional[str] = None

    # --- Notion å‡­è¯ ---
    NOTION_COOKIE: Optional[str] = None
    NOTION_SPACE_ID: Optional[str] = None
    NOTION_USER_ID: Optional[str] = None
    NOTION_USER_NAME: Optional[str] = None
    NOTION_USER_EMAIL: Optional[str] = None
    NOTION_BLOCK_ID: Optional[str] = None
    NOTION_CLIENT_VERSION: Optional[str] = "23.13.20251011.2037"

    API_REQUEST_TIMEOUT: int = 180
    NGINX_PORT: int = 8088

    # ã€æœ€ç»ˆä¿®æ­£ã€‘æ›´æ–°æ‰€æœ‰å·²çŸ¥çš„æ¨¡å‹åˆ—è¡¨
    DEFAULT_MODEL: str = "claude-sonnet-4.5"
    
    KNOWN_MODELS: List[str] = [
        "claude-sonnet-4.5",
        "gpt-5",
        "claude-opus-4.1",
        "gemini-2.5-flashï¼ˆæœªä¿®å¤ï¼Œä¸å¯ç”¨ï¼‰",
        "gemini-2.5-proï¼ˆæœªä¿®å¤ï¼Œä¸å¯ç”¨ï¼‰",
        "gpt-4.1"
    ]
    
    # ã€æœ€ç»ˆä¿®æ­£ã€‘æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œå¡«å……æ‰€æœ‰æ¨¡å‹çš„çœŸå®åå°åç§°
    MODEL_MAP: dict = {
        "claude-sonnet-4.5": "anthropic-sonnet-alt",
        "gpt-5": "openai-turbo",
        "claude-opus-4.1": "anthropic-opus-4.1",
        "gemini-2.5-flashï¼ˆæœªä¿®å¤ï¼Œä¸å¯ç”¨ï¼‰": "vertex-gemini-2.5-flash",
        "gemini-2.5-proï¼ˆæœªä¿®å¤ï¼Œä¸å¯ç”¨ï¼‰": "vertex-gemini-2.5-pro",
        "gpt-4.1": "openai-gpt-4.1"
    }

settings = Settings()

--- æ–‡ä»¶è·¯å¾„: app\providers\__init__.py ---



--- æ–‡ä»¶è·¯å¾„: app\providers\base_provider.py ---

from abc import ABC, abstractmethod
from typing import Dict, Any, Union
from fastapi.responses import StreamingResponse, JSONResponse

class BaseProvider(ABC):
    @abstractmethod
    async def chat_completion(
        self,
        request_data: Dict[str, Any]
    ) -> Union[StreamingResponse, JSONResponse]:
        pass

    @abstractmethod
    async def get_models(self) -> JSONResponse:
        pass


--- æ–‡ä»¶è·¯å¾„: app\providers\notion_provider.py ---

# app/providers/notion_provider.py
import json
import time
import logging
import uuid
import re
import cloudscraper
from typing import Dict, Any, AsyncGenerator, List, Optional, Tuple
from datetime import datetime

from fastapi import HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.concurrency import run_in_threadpool

from app.core.config import settings
from app.providers.base_provider import BaseProvider
from app.utils.sse_utils import create_sse_data, create_chat_completion_chunk, DONE_CHUNK

# è®¾ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)

class NotionAIProvider(BaseProvider):
    def __init__(self):
        self.scraper = cloudscraper.create_scraper()
        self.api_endpoints = {
            "runInference": "https://www.notion.so/api/v3/runInferenceTranscript",
            "saveTransactions": "https://www.notion.so/api/v3/saveTransactionsFanout"
        }
        
        if not all([settings.NOTION_COOKIE, settings.NOTION_SPACE_ID, settings.NOTION_USER_ID]):
            raise ValueError("é…ç½®é”™è¯¯: NOTION_COOKIE, NOTION_SPACE_ID å’Œ NOTION_USER_ID å¿…é¡»åœ¨ .env æ–‡ä»¶ä¸­å…¨éƒ¨è®¾ç½®ã€‚")

        self._warmup_session()

    def _warmup_session(self):
        try:
            logger.info("æ­£åœ¨è¿›è¡Œä¼šè¯é¢„çƒ­ (Session Warm-up)...")
            headers = self._prepare_headers()
            headers.pop("Accept", None)
            response = self.scraper.get("https://www.notion.so/", headers=headers, timeout=30)
            response.raise_for_status()
            logger.info("ä¼šè¯é¢„çƒ­æˆåŠŸã€‚")
        except Exception as e:
            logger.error(f"ä¼šè¯é¢„çƒ­å¤±è´¥: {e}", exc_info=True)
            
    async def _create_thread(self, thread_type: str) -> str:
        thread_id = str(uuid.uuid4())
        payload = {
            "requestId": str(uuid.uuid4()),
            "transactions": [{
                "id": str(uuid.uuid4()),
                "spaceId": settings.NOTION_SPACE_ID,
                "operations": [{
                    "pointer": {"table": "thread", "id": thread_id, "spaceId": settings.NOTION_SPACE_ID},
                    "path": [],
                    "command": "set",
                    "args": {
                        "id": thread_id, "version": 1, "parent_id": settings.NOTION_SPACE_ID,
                        "parent_table": "space", "space_id": settings.NOTION_SPACE_ID,
                        "created_time": int(time.time() * 1000),
                        "created_by_id": settings.NOTION_USER_ID, "created_by_table": "notion_user",
                        "messages": [], "data": {}, "alive": True, "type": thread_type
                    }
                }]
            }]
        }
        try:
            logger.info(f"æ­£åœ¨åˆ›å»ºæ–°çš„å¯¹è¯çº¿ç¨‹ (type: {thread_type})...")
            response = await run_in_threadpool(
                lambda: self.scraper.post(
                    self.api_endpoints["saveTransactions"],
                    headers=self._prepare_headers(),
                    json=payload,
                    timeout=20
                )
            )
            response.raise_for_status()
            logger.info(f"å¯¹è¯çº¿ç¨‹åˆ›å»ºæˆåŠŸ, Thread ID: {thread_id}")
            return thread_id
        except Exception as e:
            logger.error(f"åˆ›å»ºå¯¹è¯çº¿ç¨‹å¤±è´¥: {e}", exc_info=True)
            raise Exception("æ— æ³•åˆ›å»ºæ–°çš„å¯¹è¯çº¿ç¨‹ã€‚")

    async def chat_completion(self, request_data: Dict[str, Any]):
        stream = request_data.get("stream", True)

        async def stream_generator() -> AsyncGenerator[bytes, None]:
            request_id = f"chatcmpl-{uuid.uuid4()}"
            incremental_fragments: List[str] = []
            final_message: Optional[str] = None
            
            try:
                model_name = request_data.get("model", settings.DEFAULT_MODEL)
                mapped_model = settings.MODEL_MAP.get(model_name, "anthropic-sonnet-alt")
                
                thread_type = "markdown-chat" if mapped_model.startswith("vertex-") else "workflow"
                
                thread_id = await self._create_thread(thread_type)
                payload = self._prepare_payload(request_data, thread_id, mapped_model, thread_type)
                headers = self._prepare_headers()

                role_chunk = create_chat_completion_chunk(request_id, model_name, role="assistant")
                yield create_sse_data(role_chunk)

                def sync_stream_iterator():
                    try:
                        logger.info(f"è¯·æ±‚ Notion AI URL: {self.api_endpoints['runInference']}")
                        logger.info(f"è¯·æ±‚ä½“: {json.dumps(payload, indent=2, ensure_ascii=False)}")
                        
                        response = self.scraper.post(
                            self.api_endpoints['runInference'], headers=headers, json=payload, stream=True,
                            timeout=settings.API_REQUEST_TIMEOUT
                        )
                        response.raise_for_status()
                        for line in response.iter_lines():
                            if line:
                                yield line
                    except Exception as e:
                        yield e

                sync_gen = sync_stream_iterator()
              
                while True:
                    line = await run_in_threadpool(lambda: next(sync_gen, None))
                    if line is None:
                        break
                    if isinstance(line, Exception):
                        raise line

                    parsed_results = self._parse_ndjson_line_to_texts(line)
                    for text_type, content in parsed_results:
                        if text_type == 'final':
                            final_message = content
                        elif text_type == 'incremental':
                            incremental_fragments.append(content)
              
                full_response = ""
                if final_message:
                    full_response = final_message
                    logger.info(f"æˆåŠŸä» record-map æˆ– Gemini patch/event ä¸­æå–åˆ°æœ€ç»ˆæ¶ˆæ¯ã€‚")
                else:
                    full_response = "".join(incremental_fragments)
                    logger.info(f"ä½¿ç”¨æ‹¼æ¥æ‰€æœ‰å¢é‡ç‰‡æ®µçš„æ–¹å¼è·å¾—æœ€ç»ˆæ¶ˆæ¯ã€‚")

                if full_response:
                    cleaned_response = self._clean_content(full_response)
                    logger.info(f"æ¸…æ´—åçš„æœ€ç»ˆå“åº”: {cleaned_response}")
                    chunk = create_chat_completion_chunk(request_id, model_name, content=cleaned_response)
                    yield create_sse_data(chunk)
                else:
                    logger.warning("è­¦å‘Š: Notion è¿”å›çš„æ•°æ®æµä¸­æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆæ–‡æœ¬ã€‚è¯·æ£€æŸ¥æ‚¨çš„ .env é…ç½®æ˜¯å¦å…¨éƒ¨æ­£ç¡®ä¸”å‡­è¯æœ‰æ•ˆã€‚")

                final_chunk = create_chat_completion_chunk(request_id, model_name, finish_reason="stop")
                yield create_sse_data(final_chunk)
                yield DONE_CHUNK

            except Exception as e:
                error_message = f"å¤„ç† Notion AI æµæ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}"
                logger.error(error_message, exc_info=True)
                error_chunk = {"error": {"message": error_message, "type": "internal_server_error"}}
                yield create_sse_data(error_chunk)
                yield DONE_CHUNK

        if stream:
            return StreamingResponse(stream_generator(), media_type="text/event-stream")
        else:
            raise HTTPException(status_code=400, detail="æ­¤ç«¯ç‚¹å½“å‰ä»…æ”¯æŒæµå¼å“åº” (stream=true)ã€‚")

    def _prepare_headers(self) -> Dict[str, str]:
        cookie_source = (settings.NOTION_COOKIE or "").strip()
        cookie_header = cookie_source if "=" in cookie_source else f"token_v2={cookie_source}"

        return {
            "Content-Type": "application/json",
            "Accept": "application/x-ndjson",
            "Cookie": cookie_header,
            "x-notion-space-id": settings.NOTION_SPACE_ID,
            "x-notion-active-user-header": settings.NOTION_USER_ID,
            "x-notion-client-version": settings.NOTION_CLIENT_VERSION,
            "notion-audit-log-platform": "web",
            "Origin": "https://www.notion.so",
            "Referer": "https://www.notion.so/",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
        }

    def _normalize_block_id(self, block_id: str) -> str:
        if not block_id: return block_id
        b = block_id.replace("-", "").strip()
        if len(b) == 32 and re.fullmatch(r"[0-9a-fA-F]{32}", b):
            return f"{b[0:8]}-{b[8:12]}-{b[12:16]}-{b[16:20]}-{b[20:]}"
        return block_id

    def _prepare_payload(self, request_data: Dict[str, Any], thread_id: str, mapped_model: str, thread_type: str) -> Dict[str, Any]:
        req_block_id = request_data.get("notion_block_id") or settings.NOTION_BLOCK_ID
        normalized_block_id = self._normalize_block_id(req_block_id) if req_block_id else None

        context_value: Dict[str, Any] = {
            "timezone": "Asia/Shanghai",
            "spaceId": settings.NOTION_SPACE_ID,
            "userId": settings.NOTION_USER_ID,
            "userEmail": settings.NOTION_USER_EMAIL,
            "currentDatetime": datetime.now().astimezone().isoformat(),
        }
        if normalized_block_id:
            context_value["blockId"] = normalized_block_id

        config_value: Dict[str, Any]
        
        if mapped_model.startswith("vertex-"):
            logger.info(f"æ£€æµ‹åˆ° Gemini æ¨¡å‹ ({mapped_model})ï¼Œåº”ç”¨ç‰¹å®šçš„ config å’Œ contextã€‚")
            context_value.update({
                "userName": f" {settings.NOTION_USER_NAME}",
                "spaceName": f"{settings.NOTION_USER_NAME}çš„ Notion",
                "spaceViewId": "2008eefa-d0dc-80d5-9e67-000623befd8f",
                "surface": "ai_module"
            })
            config_value = {
                "type": thread_type,
                "model": mapped_model,
                "useWebSearch": True,
                "enableAgentAutomations": False, "enableAgentIntegrations": False,
                "enableBackgroundAgents": False, "enableCodegenIntegration": False,
                "enableCustomAgents": False, "enableExperimentalIntegrations": False,
                "enableLinkedDatabases": False, "enableAgentViewVersionHistoryTool": False,
                "searchScopes": [{"type": "everything"}], "enableDatabaseAgents": False,
                "enableAgentComments": False, "enableAgentForms": False,
                "enableAgentMakesFormulas": False, "enableUserSessionContext": False,
                "modelFromUser": True, "isCustomAgent": False
            }
        else:
            context_value.update({
                "userName": settings.NOTION_USER_NAME,
                "surface": "workflows"
            })
            config_value = {
                "type": thread_type,
                "model": mapped_model,
                "useWebSearch": True,
            }

        transcript = [
            {"id": str(uuid.uuid4()), "type": "config", "value": config_value},
            {"id": str(uuid.uuid4()), "type": "context", "value": context_value}
        ]
      
        for msg in request_data.get("messages", []):
            if msg.get("role") == "user":
                transcript.append({
                    "id": str(uuid.uuid4()),
                    "type": "user",
                    "value": [[msg.get("content")]],
                    "userId": settings.NOTION_USER_ID,
                    "createdAt": datetime.now().astimezone().isoformat()
                })
            elif msg.get("role") == "assistant":
                transcript.append({"id": str(uuid.uuid4()), "type": "agent-inference", "value": [{"type": "text", "content": msg.get("content")}]})

        payload = {
            "traceId": str(uuid.uuid4()),
            "spaceId": settings.NOTION_SPACE_ID,
            "transcript": transcript,
            "threadId": thread_id,
            "createThread": False,
            "isPartialTranscript": True,
            "asPatchResponse": True,
            "generateTitle": True,
            "saveAllThreadOperations": True,
            "threadType": thread_type
        }

        if mapped_model.startswith("vertex-"):
            logger.info("ä¸º Gemini è¯·æ±‚æ·»åŠ  debugOverridesã€‚")
            payload["debugOverrides"] = {
                "emitAgentSearchExtractedResults": True,
                "cachedInferences": {},
                "annotationInferences": {},
                "emitInferences": False
            }
        
        return payload

    def _clean_content(self, content: str) -> str:
        if not content:
            return ""
            
        content = re.sub(r'<lang primary="[^"]*"\s*/>\n*', '', content)
        content = re.sub(r'<thinking>[\s\S]*?</thinking>\s*', '', content, flags=re.IGNORECASE)
        content = re.sub(r'<thought>[\s\S]*?</thought>\s*', '', content, flags=re.IGNORECASE)
        
        content = re.sub(r'^.*?Chinese whatmodel I am.*?Theyspecifically.*?requested.*?me.*?to.*?reply.*?in.*?Chinese\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?This.*?is.*?a.*?straightforward.*?question.*?about.*?my.*?identity.*?asan.*?AI.*?assistant\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?Idon\'t.*?need.*?to.*?use.*?any.*?tools.*?for.*?this.*?-\s*it\'s.*?asimple.*?informational.*?response.*?aboutwhat.*?I.*?am\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?Sincethe.*?user.*?asked.*?in.*?Chinese.*?and.*?specifically.*?requested.*?a.*?Chinese.*?response.*?I.*?should.*?respond.*?in.*?Chinese\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?What model are you.*?in Chinese and specifically requesting.*?me.*?to.*?reply.*?in.*?Chinese\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?This.*?is.*?a.*?question.*?about.*?my.*?identity.*?not requiring.*?any.*?tool.*?use.*?I.*?should.*?respond.*?directly.*?to.*?the.*?user.*?in.*?Chinese.*?as.*?requested\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?I.*?should.*?identify.*?myself.*?as.*?Notion.*?AI.*?as.*?mentioned.*?in.*?the.*?system.*?prompt.*?\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        content = re.sub(r'^.*?I.*?should.*?not.*?make.*?specific.*?claims.*?about.*?the.*?underlying.*?model.*?architecture.*?since.*?that.*?information.*?is.*?not.*?provided.*?in.*?my.*?context\.\s*', '', content, flags=re.IGNORECASE | re.DOTALL)
        
        return content.strip()

    def _parse_ndjson_line_to_texts(self, line: bytes) -> List[Tuple[str, str]]:
        results: List[Tuple[str, str]] = []
        try:
            s = line.decode("utf-8", errors="ignore").strip()
            if not s: return results
            
            data = json.loads(s)
            logger.debug(f"åŸå§‹å“åº”æ•°æ®: {json.dumps(data, ensure_ascii=False)}")
            
            # æ ¼å¼1: Gemini è¿”å›çš„ markdown-chat äº‹ä»¶
            if data.get("type") == "markdown-chat":
                content = data.get("value", "")
                if content:
                    logger.info("ä» 'markdown-chat' ç›´æ¥äº‹ä»¶ä¸­æå–åˆ°å†…å®¹ã€‚")
                    results.append(('final', content))

            # æ ¼å¼2: Claude å’Œ GPT è¿”å›çš„è¡¥ä¸æµï¼Œä»¥åŠ Gemini çš„ patch æ ¼å¼
            elif data.get("type") == "patch" and "v" in data:
                for operation in data.get("v", []):
                    if not isinstance(operation, dict): continue
                    
                    op_type = operation.get("o")
                    path = operation.get("p", "")
                    value = operation.get("v")
                    
                    # ã€ä¿®æ”¹ã€‘Gemini çš„å®Œæ•´å†…å®¹ patch æ ¼å¼
                    if op_type == "a" and path.endswith("/s/-") and isinstance(value, dict) and value.get("type") == "markdown-chat":
                        content = value.get("value", "")
                        if content:
                            logger.info("ä» 'patch' (Gemini-style) ä¸­æå–åˆ°å®Œæ•´å†…å®¹ã€‚")
                            results.append(('final', content))
                    
                    # ã€ä¿®æ”¹ã€‘Gemini çš„å¢é‡å†…å®¹ patch æ ¼å¼
                    elif op_type == "x" and "/s/" in path and path.endswith("/value") and isinstance(value, str):
                        content = value
                        if content:
                            logger.info(f"ä» 'patch' (Geminiå¢é‡) ä¸­æå–åˆ°å†…å®¹: {content}")
                            results.append(('incremental', content))
                    
                    # ã€ä¿®æ”¹ã€‘Claude å’Œ GPT çš„å¢é‡å†…å®¹ patch æ ¼å¼
                    elif op_type == "x" and "/value/" in path and isinstance(value, str):
                        content = value
                        if content:
                            logger.info(f"ä» 'patch' (Claude/GPTå¢é‡) ä¸­æå–åˆ°å†…å®¹: {content}")
                            results.append(('incremental', content))
                    
                    # ã€ä¿®æ”¹ã€‘Claude å’Œ GPT çš„å®Œæ•´å†…å®¹ patch æ ¼å¼
                    elif op_type == "a" and path.endswith("/value/-") and isinstance(value, dict) and value.get("type") == "text":
                        content = value.get("content", "")
                        if content:
                            logger.info("ä» 'patch' (Claude/GPT-style) ä¸­æå–åˆ°å®Œæ•´å†…å®¹ã€‚")
                            results.append(('final', content))

            # æ ¼å¼3: å¤„ç†record-mapç±»å‹çš„æ•°æ®
            elif data.get("type") == "record-map" and "recordMap" in data:
                record_map = data["recordMap"]
                if "thread_message" in record_map:
                    for msg_id, msg_data in record_map["thread_message"].items():
                        value_data = msg_data.get("value", {}).get("value", {})
                        step = value_data.get("step", {})
                        if not step: continue

                        content = ""
                        step_type = step.get("type")

                        if step_type == "markdown-chat":
                            content = step.get("value", "")
                        elif step_type == "agent-inference":
                            agent_values = step.get("value", [])
                            if isinstance(agent_values, list):
                                for item in agent_values:
                                    if isinstance(item, dict) and item.get("type") == "text":
                                        content = item.get("content", "")
                                        break
                        
                        if content and isinstance(content, str):
                            logger.info(f"ä» record-map (type: {step_type}) æå–åˆ°æœ€ç»ˆå†…å®¹ã€‚")
                            results.append(('final', content))
                            break 
    
        except (json.JSONDecodeError, AttributeError) as e:
            logger.warning(f"è§£æNDJSONè¡Œå¤±è´¥: {e} - Line: {line.decode('utf-8', errors='ignore')}")
        
        return results

    async def get_models(self) -> JSONResponse:
        model_data = {
            "object": "list",
            "data": [
                {"id": name, "object": "model", "created": int(time.time()), "owned_by": "lzA6"}
                for name in settings.KNOWN_MODELS
            ]
        }
        return JSONResponse(content=model_data)


--- æ–‡ä»¶è·¯å¾„: app\utils\sse_utils.py ---

# app/utils/sse_utils.py
import json
import time
from typing import Dict, Any, Optional

DONE_CHUNK = b"data: [DONE]\n\n"

def create_sse_data(data: Dict[str, Any]) -> bytes:
    return f"data: {json.dumps(data)}\n\n".encode('utf-8')

def create_chat_completion_chunk(
    request_id: str,
    model: str,
    content: Optional[str] = None,
    finish_reason: Optional[str] = None,
    role: Optional[str] = None
) -> Dict[str, Any]:
    delta: Dict[str, Any] = {}
    if role is not None:
        delta["role"] = role
    if content is not None:
        delta["content"] = content

    return {
        "id": request_id,
        "object": "chat.completion.chunk",
        "created": int(time.time()),
        "model": model,
        "choices": [
            {
                "index": 0,
                "delta": delta,
                "finish_reason": finish_reason
            }
        ]
    }
```

---

## ğŸ“Š ç»Ÿè®¡

- æ–‡ä»¶æ•°é‡ï¼š15
- æ€»è¡Œæ•°ï¼š2,164
- æ€»å­—ç¬¦æ•°ï¼š75,285